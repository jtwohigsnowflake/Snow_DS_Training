{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b5dd094-07b5-40b9-be25-be16cb8ccd3b",
   "metadata": {
    "collapsed": false,
    "name": "Intro"
   },
   "source": [
    "# Snowflake to Model Deployment Demo\n",
    "\n",
    "In this demo, you'll walk through a complete machine learning pipeline from data ingestion to deployment and inference using containerized infrastructure.\n",
    "\n",
    "## Demo Overview\n",
    "\n",
    "This demo includes the following key steps:\n",
    "\n",
    "1. **Data Ingestion from Snowflake**  \n",
    "   Pull structured Titanic dataset from Snowflake.\n",
    "\n",
    "2. **Feature Engineering**  \n",
    "   Transform raw data into meaningful features for model training.\n",
    "\n",
    "3. **Model Training with XGBoost**  \n",
    "   Use XGBoost to train a classification model on the engineered dataset.\n",
    "\n",
    "4. **Model Deployment**  \n",
    "   Register and deploy the trained model.\n",
    "\n",
    "5. **Batch Inference**  \n",
    "   Call the deployed model to make predictions on new batches of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346ac9c-b21f-44fd-b6a1-70de9924cae4",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "pip_install",
    "resultHeight": 306
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Centralize all configuration variables here for easy management\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = \"TITANIC\"\n",
    "TARGET_COLUMN = \"SURVIVED\"\n",
    "\n",
    "# Data configuration\n",
    "SOURCE_CSV = \"data/titanic_snowflake.csv\"\n",
    "RAW_TABLE = \"TITANIC_RAW\"\n",
    "PREDICT_TABLE = \"TITANIC_PREDICT\"\n",
    "DYNAMIC_TABLE = \"TITANIC_BATCH_INFERENCE\"\n",
    "\n",
    "# Model training configuration\n",
    "TRAIN_SIZE = 0.70\n",
    "RANDOM_STATE = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "imports",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56066407-bba0-4d10-98f5-2f6dae0145d3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_data",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Load and perform initial data cleaning\n",
    "titanic = pd.read_csv(SOURCE_CSV)\n",
    "\n",
    "print(f\"Original shape: {titanic.shape}\")\n",
    "print(f\"Columns: {list(titanic.columns)}\")\n",
    "\n",
    "# Drop columns not useful for modeling\n",
    "titanic = titanic.drop([\"AGE\", \"DECK\", \"ALIVE\", \"ADULT_MALE\", \n",
    "                        \"EMBARKED\", \"PCLASS\", \"ALONE\", \"SEX\"], axis=1)\n",
    "\n",
    "print(f\"Shape after dropping columns: {titanic.shape}\")\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53f4ef-a085-439c-ab79-68c4a0deec18",
   "metadata": {
    "collapsed": false,
    "name": "Get_Data_From_Snowflake"
   },
   "source": [
    "## Step 1: Data Ingestion to Snowflake\n",
    "\n",
    "This demonstrates the typical workflow of writing data to Snowflake and reading it back.\n",
    "\n",
    "**Pattern:**\n",
    "1. Convert pandas DataFrame → Snowpark DataFrame\n",
    "2. Write to Snowflake table\n",
    "3. Read back from Snowflake table → pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e117fbf-2fc7-444c-a99a-21b6a1aaffac",
   "metadata": {
    "language": "python",
    "name": "write_to_table"
   },
   "outputs": [],
   "source": [
    "# Write pandas DataFrame to Snowflake table\n",
    "titanic_sf = session.create_dataframe(titanic)\n",
    "titanic_sf.write.mode(\"overwrite\").save_as_table(RAW_TABLE)\n",
    "\n",
    "print(f\"✓ Data written to {RAW_TABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b684830-9d7b-4cce-842d-ebcb061935a3",
   "metadata": {
    "language": "python",
    "name": "Read_table_pandas"
   },
   "outputs": [],
   "source": [
    "# Read table from Snowflake back to pandas\n",
    "titanic_raw = session.table(RAW_TABLE).to_pandas()\n",
    "print(f\"✓ Loaded {len(titanic_raw)} rows from {RAW_TABLE}\")\n",
    "titanic_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c4452f-6edd-4eae-939e-361999c72704",
   "metadata": {
    "language": "sql",
    "name": "df_sql"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- You can also query directly with SQL\n",
    "SELECT * FROM {{RAW_TABLE}} LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "627ff33f-bc9d-41ab-8fc7-a51bdfa72a90",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "## Step 2: Feature Engineering\n",
    "\n",
    "Prepare data for machine learning by:\n",
    "1. Handling missing values\n",
    "2. Creating dummy variables for categorical features\n",
    "3. Converting boolean columns to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bb52d-2b0d-45ff-aa1d-a8df0bbb127b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "drop_nulls",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(f\"Missing values before: {titanic.isnull().sum().sum()}\")\n",
    "titanic.dropna(inplace=True)\n",
    "print(f\"Missing values after: {titanic.isnull().sum().sum()}\")\n",
    "print(f\"Rows remaining: {len(titanic)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1acb42-85cd-4fc2-a1e6-edcc5704ec45",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_dummies",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Create dummy variables and convert booleans to integers\n",
    "titanic = pd.get_dummies(titanic, drop_first=True)\n",
    "titanic = titanic.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)\n",
    "\n",
    "print(\"Final feature types:\")\n",
    "print(titanic.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab08374-e406-4a7c-9912-9a92567f5c74",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "x_y",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "x = titanic.drop(TARGET_COLUMN, axis=1)\n",
    "y = titanic[TARGET_COLUMN]\n",
    "\n",
    "print(f\"Features shape: {x.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8ccdf-943d-4530-9458-f68f93b96dd6",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "split_test_train",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    x, y, train_size=TRAIN_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Training set: {xtrain.shape}\")\n",
    "print(f\"Test set: {xtest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "544a1c2f-3a07-46e5-a3ee-f72c792fe7ea",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "param_grid_def",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "## Step 3: Model Training with Hyperparameter Tuning\n",
    "\n",
    "Using GridSearchCV to find optimal XGBoost parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84958eaf-df33-48ba-baa9-14659c493135",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "train_model",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.1, 0.5],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"min_child_weight\": [1, 3]\n",
    "}\n",
    "\n",
    "# Train model with grid search\n",
    "model = XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Training model with GridSearchCV...\")\n",
    "grid_search.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597a1b5-fa80-482b-9279-96dc72020697",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_best_params",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Evaluate best model\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(xtest, ytest)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best CV Score: {best_score:.4f}\")\n",
    "print(f\"Test Score: {test_score:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e53e21-e9d6-453d-8149-448270476258",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_metrics",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Prepare metrics for model registry\n",
    "metrics = {\n",
    "    \"cv_accuracy\": best_score,\n",
    "    \"test_accuracy\": test_score,\n",
    "    \"best_params\": str(best_params)\n",
    "}\n",
    "\n",
    "print(\"Metrics to log:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "b263614f-9d84-463f-a37d-f4b787889ec4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "register_model",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "## Step 4: Model Registration\n",
    "\n",
    "Register the trained model in Snowflake Model Registry with:\n",
    "- **target_platforms=[\"WAREHOUSE\"]** - Enables SQL-based inference\n",
    "- **Version control** - Automatic versioning with metadata\n",
    "- **Sample input data** - For schema inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5b6b9-9b81-4671-b3a2-4d23d437023e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_models",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Register model in Snowflake Model Registry\n",
    "reg = Registry(session=session)\n",
    "\n",
    "sample_input = xtrain.sample(n=1)\n",
    "\n",
    "print(f\"Registering model '{MODEL_NAME}' to Snowflake Model Registry...\")\n",
    "\n",
    "titanic_model = reg.log_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    options={\"relax_version\": True},\n",
    "    target_platforms=[\"WAREHOUSE\"],  # Enables SQL-based inference\n",
    "    model=best_model,\n",
    "    sample_input_data=sample_input,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "print(f\"✓ Model registered: {titanic_model.model_name} v{titanic_model.version_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538ef69-e58c-4c1d-8af0-3c99c0e9f14e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "show_model_versions",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# View all models in registry\n",
    "models_df = reg.show_models()\n",
    "models_df[models_df['name'] == MODEL_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ebd8f-407a-4aa1-9cf7-5ac161e8fbd1",
   "metadata": {
    "language": "python",
    "name": "Show_Recent_Model"
   },
   "outputs": [],
   "source": [
    "# View all versions of this model\n",
    "versions = reg.get_model(MODEL_NAME).show_versions()\n",
    "versions.sort_values(by='created_on', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fde38-6f47-4919-8eca-19619f1a8818",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "promote_model",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Get the most recent model version\n",
    "model_version = reg.get_model(MODEL_NAME).last()\n",
    "version_name = model_version.version_name\n",
    "\n",
    "print(f\"Using model version: {version_name}\")\n",
    "model_version"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "51a69210-dc84-4d01-b079-dd726b288c31",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "predict_remotely",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "## Step 5: Batch Inference - Method 1 (Python)\n",
    "\n",
    "Use the model registry's `run()` method to generate predictions directly in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c919f2-8069-4dcf-9cff-999f9815602f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "write_test_to_SF",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Run batch inference using Python\n",
    "print(f\"Running batch inference on {len(xtest)} test records...\")\n",
    "\n",
    "remote_prediction = model_version.run(xtest, function_name=\"PREDICT_PROBA\")\n",
    "\n",
    "print(f\"✓ Predictions generated\")\n",
    "remote_prediction.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "beb2ed35-07bb-4ba3-b209-32a25fb01e72",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "predict_with_sql",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "## Step 6: Batch Inference - Method 2 (SQL)\n",
    "\n",
    "Write test data to Snowflake table and score it using SQL with model UDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae35b82-a01b-458b-a91d-62aeefbe54e5",
   "metadata": {
    "collapsed": false,
    "name": "Dyn_table_instructions"
   },
   "source": [
    "# Write test data to Snowflake for SQL-based inference\n",
    "test_sf = session.create_dataframe(xtest.reset_index(drop=True))\n",
    "test_sf.write.mode(\"overwrite\").save_as_table(PREDICT_TABLE)\n",
    "\n",
    "print(f\"✓ Test data written to {PREDICT_TABLE}\")\n",
    "session.table(PREDICT_TABLE).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b885f-7e8d-465b-92aa-55ce17f13ba2",
   "metadata": {
    "language": "python",
    "name": "get_warehouse_dnmc_tbl"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- SQL-based batch inference using model UDF\n",
    "-- The model is called as: MODEL_NAME!FUNCTION_NAME(*)\n",
    "\n",
    "SELECT \n",
    "    *,\n",
    "    ROUND({{MODEL_NAME}}!PREDICT_PROBA(*):output_feature_0, 2) AS survival_probability\n",
    "FROM {{PREDICT_TABLE}}\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "75be2d75-b37c-493b-b46d-284d3516fcda",
   "metadata": {
    "language": "sql",
    "name": "Create_Dynamic_Table"
   },
   "outputs": [],
   "source": [
    "## Step 7: Batch Inference - Method 3 (Dynamic Tables)\n",
    "\n",
    "**Dynamic Tables** provide automated, continuously updated batch inference:\n",
    "\n",
    "- **Automated Refresh**: Runs inference automatically based on `target_lag`\n",
    "- **Incremental Updates**: Only processes new/changed data\n",
    "- **Production Ready**: No scheduled jobs or orchestration needed\n",
    "\n",
    "### Demo Workflow:\n",
    "1. Create dynamic table with model inference\n",
    "2. Insert new data into source table\n",
    "3. Dynamic table automatically refreshes within target_lag (1 minute)\n",
    "4. View updated predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b199b67a-d84a-4d01-ba0d-1e693d1418da",
   "metadata": {
    "language": "sql",
    "name": "Insert_data"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Create dynamic table for automated batch inference\n",
    "CREATE OR REPLACE DYNAMIC TABLE {{DYNAMIC_TABLE}}\n",
    "TARGET_LAG = '1 minute' \n",
    "WAREHOUSE = {{current_wh}} \n",
    "AS\n",
    "SELECT \n",
    "    *,\n",
    "    ROUND({{MODEL_NAME}}!PREDICT_PROBA(*):output_feature_0, 2) AS survival_probability\n",
    "FROM {{PREDICT_TABLE}};\n",
    "\n",
    "-- View initial results\n",
    "SELECT * FROM {{DYNAMIC_TABLE}} LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "0015cf7c-9013-403a-aaac-ecc62af1c349",
   "metadata": {
    "language": "sql",
    "name": "drop_dynamic_table"
   },
   "outputs": [],
   "source": [
    "## Step 8: Test Dynamic Table with New Data\n",
    "\n",
    "Insert new records and observe automatic inference within 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "%%sql\n",
    "-- Drop all demo resources\n",
    "DROP DYNAMIC TABLE IF EXISTS {{DYNAMIC_TABLE}};\n",
    "DROP TABLE IF EXISTS {{PREDICT_TABLE}};\n",
    "DROP TABLE IF EXISTS {{RAW_TABLE}};\n",
    "\n",
    "-- Note: Model remains in registry for reuse. \n",
    "-- To remove model: reg.delete_model(MODEL_NAME)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## Step 9: Cleanup Resources\n",
    "\n",
    "Run this cell to remove all demo resources when complete."
   ],
   "attachments": {}
  },
  {
   "cell_type": "code",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "# Check dynamic table refresh status\n",
    "refresh_info = session.sql(f\"\"\"\n",
    "    SELECT \n",
    "        scheduling_state,\n",
    "        last_successful_run_timestamp,\n",
    "        next_scheduled_refresh_time\n",
    "    FROM TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY(\n",
    "        NAME => '{DYNAMIC_TABLE}'\n",
    "    ))\n",
    "    ORDER BY last_successful_run_timestamp DESC\n",
    "    LIMIT 1\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "refresh_info"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "%%sql\n",
    "-- Insert new records to trigger dynamic table refresh\n",
    "INSERT INTO {{PREDICT_TABLE}} (\n",
    "    SIBSP, PARCH, FARE, CLASS_SECOND, CLASS_THIRD,\n",
    "    WHO_MAN, WHO_WOMAN,\n",
    "    EMBARK_TOWN_QUEENSTOWN, EMBARK_TOWN_SOUTHAMPTON\n",
    ") VALUES\n",
    "(0, 0, 10.5, 0, 1, 1, 0, 1, 0),\n",
    "(2, 1, 23.0, 1, 0, 0, 1, 0, 1),\n",
    "(0, 2, 15.75, 1, 0, 0, 1, 1, 0),\n",
    "(1, 1, 7.925, 0, 1, 1, 0, 0, 1),\n",
    "(0, 0, 7.75, 0, 1, 1, 0, 0, 1);\n",
    "\n",
    "-- Wait ~1 minute, then check the dynamic table for new predictions\n",
    "SELECT COUNT(*) AS total_records FROM {{DYNAMIC_TABLE}};"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "chase.romano@snowflake.com",
   "authorId": "4927852566776",
   "authorName": "CHASE",
   "lastEditTime": 1758643964422,
   "notebookId": "5gejgr6mrzkifjzg2pl5",
   "sessionId": "621f6211-383b-4abf-96d7-e23d5a27615b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}