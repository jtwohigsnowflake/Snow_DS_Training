{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "_Imports"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import snowflake.ml.modeling.preprocessing as snowml\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "from snowflake.snowpark.functions import col, to_timestamp, min, max, month, dayofweek, dayofyear, avg, date_add, sql_expr\n",
    "from snowflake.snowpark import Window\n",
    "from snowflake.snowpark.types import IntegerType\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "#Snowflake feature store\n",
    "from snowflake.ml.feature_store import FeatureStore, FeatureView, Entity, CreationMode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "VERSION_NUM = '1'\n",
    "DB = 'DEMO'\n",
    "SCHEMA = 'PUBLIC'\n",
    "COMPUTE_WAREHOUSE = 'DEMO_WH'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6c164-fb27-4858-bb02-a205ae1b27e2",
   "metadata": {
    "collapsed": false,
    "name": "_Model2_Summary"
   },
   "source": [
    "We have now shown how you can easily build, iterate on, and deploy models.  Now let's dive in to some more advanced features and explain why they are important for large scale production ML workloads.  This will include.... \n",
    "\n",
    "- Feature Store\n",
    "- Experiment Tracking\n",
    "- Distributed multi node training with Ray\n",
    "- Real time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c690d-9b4f-4a8c-98bf-a8e116f78448",
   "metadata": {
    "collapsed": false,
    "name": "_Exp_Tracking"
   },
   "source": [
    "## Time for Feature Store, Experiment Tracking, and distributed HPO with Ray!\n",
    "\n",
    "Experiment Tracking provides a mechanism for creating experiments and logging runs within Snowflake from any development environment. This capability allows you to log key pieces of information regarding your model training runs such as model parameters and metrics. In the UI, you can deep dive into a particular run or compare multiple runs to find the optimal model.\n",
    "Below we will train multiple models using distributed HPO and log results to the Experiment Tracker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a139e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Reading table data...\")\n",
    "    df = session.table(f\"{DB}.{SCHEMA}.MORTGAGE_LENDING_DEMO_DATA\")\n",
    "    df.show()\n",
    "except:\n",
    "    print(\"Table not found! Uploading data to snowflake table\")\n",
    "    df_pandas = pd.read_csv(\"MORTGAGE_LENDING_DEMO_DATA.csv.zip\")\n",
    "    session.write_pandas(df_pandas, table_name=\"MORTGAGE_LENDING_DEMO_DATA\",database= DB,schema=SCHEMA, auto_create_table=True)\n",
    "    df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b51109-40d5-4c9c-b798-e57e4fce4947",
   "metadata": {
    "language": "python",
    "name": "_Feat_eng_FS"
   },
   "outputs": [],
   "source": [
    "df.select(min('TS'), max('TS'))\n",
    "\n",
    "#Get current date and time\n",
    "current_time = datetime.now()\n",
    "df_max_time = datetime.strptime(str(df.select(max(\"TS\")).collect()[0][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "#Find delta between latest existing timestamp and today's date\n",
    "timedelta = current_time- df_max_time\n",
    "\n",
    "#Update timestamps to represent last ~1 year from today's date\n",
    "df.select(min(date_add(to_timestamp(\"TS\"), timedelta.days-1)), max(date_add(to_timestamp(\"TS\"), timedelta.days-1)))\n",
    "\n",
    "#Create a dict with keys for feature names and values containing transform code\n",
    "\n",
    "feature_eng_dict = dict()\n",
    "\n",
    "#Timstamp features\n",
    "feature_eng_dict[\"TIMESTAMP\"] = date_add(to_timestamp(\"TS\"), timedelta.days-1)\n",
    "feature_eng_dict[\"MONTH\"] = month(\"TIMESTAMP\")\n",
    "feature_eng_dict[\"DAY_OF_YEAR\"] = dayofyear(\"TIMESTAMP\") \n",
    "feature_eng_dict[\"DOTW\"] = dayofweek(\"TIMESTAMP\")\n",
    "\n",
    "# df= df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\n",
    "\n",
    "#Income and loan features\n",
    "feature_eng_dict[\"LOAN_AMOUNT\"] = col(\"LOAN_AMOUNT_000s\")*1000\n",
    "feature_eng_dict[\"INCOME\"] = col(\"APPLICANT_INCOME_000s\")*1000\n",
    "feature_eng_dict[\"INCOME_LOAN_RATIO\"] = col(\"INCOME\")/col(\"LOAN_AMOUNT\")\n",
    "\n",
    "county_window_spec = Window.partition_by(\"COUNTY_NAME\")\n",
    "feature_eng_dict[\"MEAN_COUNTY_INCOME\"] = avg(col(\"INCOME\").cast(IntegerType())).over(county_window_spec).astype(IntegerType())\n",
    "feature_eng_dict[\"HIGH_INCOME_FLAG\"] = (col(\"INCOME\")>col(\"MEAN_COUNTY_INCOME\")).astype(IntegerType())\n",
    "feature_eng_dict[\"AVG_THIRTY_DAY_LOAN_AMOUNT\"] =  sql_expr(\"\"\"AVG(LOAN_AMOUNT) OVER (PARTITION BY COUNTY_NAME ORDER BY TIMESTAMP  \n",
    "                                                            RANGE BETWEEN INTERVAL '30 DAYS' PRECEDING AND CURRENT ROW)\"\"\")\n",
    "\n",
    "df = df.with_columns(feature_eng_dict.keys(), feature_eng_dict.values())\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b23db59-bed8-41eb-8eb3-33fbf1ca42f6",
   "metadata": {
    "language": "python",
    "name": "_FS_Creation"
   },
   "outputs": [],
   "source": [
    "fs = FeatureStore(\n",
    "    session=session, \n",
    "    database=DB, \n",
    "    name=SCHEMA, \n",
    "    default_warehouse=COMPUTE_WAREHOUSE,\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    ")\n",
    "\n",
    "fs.list_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b814ba-e765-4f6b-b971-757be02d9bd8",
   "metadata": {
    "language": "python",
    "name": "_Entities"
   },
   "outputs": [],
   "source": [
    "#First try to retrieve an existing entity definition, if not define a new one and register\n",
    "try:\n",
    "    #retrieve existing entity\n",
    "    loan_id_entity = fs.get_entity('LOAN_ENTITY') \n",
    "    print('Retrieved existing entity')\n",
    "except:\n",
    "#define new entity\n",
    "    loan_id_entity = Entity(\n",
    "        name = \"LOAN_ENTITY\",\n",
    "        join_keys = [\"LOAN_ID\"],\n",
    "        desc = \"Features defined on a per loan level\")\n",
    "    #register\n",
    "    fs.register_entity(loan_id_entity)\n",
    "    print(\"Registered new entity\")\n",
    "\n",
    "#Create a dataframe with just the ID, timestamp, and engineered features. We will use this to define our feature view\n",
    "feature_df = df.select([\"LOAN_ID\"]+list(feature_eng_dict.keys()))\n",
    "feature_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89c781-02ca-4ca3-87c2-31f1d75daf4d",
   "metadata": {
    "language": "python",
    "name": "_Feature_View"
   },
   "outputs": [],
   "source": [
    "#define and register feature view\n",
    "loan_fv = FeatureView(\n",
    "    name=\"Mortgage_Feature_View\",\n",
    "    entities=[loan_id_entity],\n",
    "    feature_df=feature_df,\n",
    "    timestamp_col=\"TIMESTAMP\",\n",
    "    refresh_freq=\"1 day\")\n",
    "\n",
    "#add feature level descriptions\n",
    "\n",
    "loan_fv = loan_fv.attach_feature_desc(\n",
    "    {\n",
    "        \"MONTH\": \"Month of loan\",\n",
    "        \"DAY_OF_YEAR\": \"Day of calendar year of loan\",\n",
    "        \"DOTW\": \"Day of the week of loan\",\n",
    "        \"LOAN_AMOUNT\": \"Loan amount in $USD\",\n",
    "        \"INCOME\": \"Household income in $USD\",\n",
    "        \"INCOME_LOAN_RATIO\": \"Ratio of LOAN_AMOUNT/INCOME\",\n",
    "        \"MEAN_COUNTY_INCOME\": \"Average household income aggregated at county level\",\n",
    "        \"HIGH_INCOME_FLAG\": \"Binary flag to indicate whether household income is higher than MEAN_COUNTY_INCOME\",\n",
    "        \"AVG_THIRTY_DAY_LOAN_AMOUNT\": \"Rolling 30 day average of LOAN_AMOUNT\"\n",
    "    }\n",
    ")\n",
    "\n",
    "loan_fv = fs.register_feature_view(loan_fv, version=VERSION_NUM, overwrite=True)\n",
    "\n",
    "fs.list_feature_views()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680110a-06b1-4312-a3fd-fb0e59579fd5",
   "metadata": {
    "language": "python",
    "name": "_Get_Dataset"
   },
   "outputs": [],
   "source": [
    "ds = fs.generate_dataset(\n",
    "    name=f\"MORTGAGE_DATASET_EXTENDED_FEATURES_{VERSION_NUM}\",\n",
    "    spine_df=df.select(\"LOAN_ID\", \"TIMESTAMP\", \"LOAN_PURPOSE_NAME\",\"MORTGAGERESPONSE\"), #only need the features used to fetch rest of feature view\n",
    "    features=[loan_fv],\n",
    "    spine_timestamp_col=\"TIMESTAMP\",\n",
    "    spine_label_cols=[\"MORTGAGERESPONSE\"]\n",
    ")\n",
    "\n",
    "#Convert Dataset to Snowpark Dataframe\n",
    "\n",
    "ds_sp = ds.read.to_snowpark_dataframe()\n",
    "ds_sp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f936773-98dc-4ca6-b424-d0b647cd5b41",
   "metadata": {
    "language": "python",
    "name": "_FV_OHE"
   },
   "outputs": [],
   "source": [
    "import snowflake.ml.modeling.preprocessing as snowml\n",
    "from snowflake.snowpark.types import StringType\n",
    "\n",
    "OHE_COLS = ds_sp.select([col.name for col in ds_sp.schema if col.datatype ==StringType()]).columns\n",
    "OHE_POST_COLS = [i+\"_OHE\" for i in OHE_COLS]\n",
    "\n",
    "\n",
    "# Encode categoricals to numeric columns\n",
    "snowml_ohe = snowml.OneHotEncoder(input_cols=OHE_COLS, output_cols = OHE_COLS, drop_input_cols=True)\n",
    "ds_sp_ohe = snowml_ohe.fit(ds_sp).transform(ds_sp)\n",
    "\n",
    "#Rename columns to avoid double nested quotes and white space chars\n",
    "rename_dict = {}\n",
    "for i in ds_sp_ohe.columns:\n",
    "    if '\"' in i:\n",
    "        rename_dict[i] = i.replace('\"','').replace(' ', '_')\n",
    "\n",
    "ds_sp_ohe = ds_sp_ohe.rename(rename_dict)\n",
    "ds_sp_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a53bb13-0a30-48c7-abf4-09198d89b8ea",
   "metadata": {
    "language": "python",
    "name": "_Train_test"
   },
   "outputs": [],
   "source": [
    "train, test = ds_sp_ohe.random_split(weights=[0.70, 0.30], seed=0)\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "train_pd = train.to_pandas()\n",
    "test_pd = test.to_pandas()\n",
    "\n",
    "# Convert all boolean columns to integers\n",
    "train_pd = train_pd.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)\n",
    "train_pd.columns = [re.sub(r'[^a-zA-Z0-9]+', '_', col.upper()) for col in train_pd.columns]\n",
    "\n",
    "test_pd = test_pd.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)\n",
    "test_pd.columns = [re.sub(r'[^a-zA-Z0-9]+', '_', col.upper()) for col in test_pd.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbfd4be-ede2-4db3-b364-3b8fd2212a2b",
   "metadata": {
    "language": "python",
    "name": "_Base_Model"
   },
   "outputs": [],
   "source": [
    "#Define model config\n",
    "xgb_base = XGBClassifier(\n",
    "    max_depth=50,\n",
    "    n_estimators=3,\n",
    "    learning_rate = 0.75,\n",
    "    booster = 'gbtree')\n",
    "\n",
    "#Split train data into X, y\n",
    "X_train_pd = train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1) #remove\n",
    "y_train_pd = train_pd.MORTGAGERESPONSE\n",
    "\n",
    "#train model\n",
    "xgb_base.fit(X_train_pd,y_train_pd)\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "train_preds_base = xgb_base.predict(X_train_pd) #update this line with correct ata\n",
    "\n",
    "f1_base_train = round(f1_score(y_train_pd, train_preds_base),4)\n",
    "precision_base_train = round(precision_score(y_train_pd, train_preds_base),4)\n",
    "recall_base_train = round(recall_score(y_train_pd, train_preds_base),4)\n",
    "\n",
    "print(f'F1: {f1_base_train} \\nPrecision {precision_base_train} \\nRecall: {recall_base_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297f3c9-c649-4a31-9370-b8a5ad460f6e",
   "metadata": {
    "language": "python",
    "name": "_Log_Base_Model"
   },
   "outputs": [],
   "source": [
    "#Create a snowflake model registry object \n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "# Define model name\n",
    "model_name = f\"MORTGAGE_LENDING_MLOPS_{VERSION_NUM}\"\n",
    "\n",
    "# Create a registry to log the model to\n",
    "model_registry = Registry(session=session, \n",
    "                          database_name=DB, \n",
    "                          schema_name=SCHEMA,\n",
    "                          options={\"enable_monitoring\": True})\n",
    "\n",
    "#Log the base model to the model registry (if not already there)\n",
    "base_version_name = 'XGB_BASE'\n",
    "\n",
    "try:\n",
    "    #Check for existing model\n",
    "    mv_base = model_registry.get_model(model_name).version(base_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    print(\"Logging new model version...\")\n",
    "    #Log model to registry\n",
    "    mv_base = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=xgb_base, \n",
    "        version_name=base_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100), #using snowpark df to maintain lineage\n",
    "        comment = f\"\"\"ML model for predicting loan approval likelihood.\n",
    "                    This model was trained using XGBoost classifier.\n",
    "                    Hyperparameters used were:\n",
    "                    max_depth={xgb_base.max_depth}, \n",
    "                    n_estimators={xgb_base.n_estimators}, \n",
    "                    learning_rate = {xgb_base.learning_rate}, \n",
    "                    algorithm = {xgb_base.booster}\n",
    "                    \"\"\",\n",
    "        target_platforms= [\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n",
    "        options= {\"enable_explainability\": True}\n",
    "\n",
    "    )\n",
    "    \n",
    "    #set metrics\n",
    "    mv_base.set_metric(metric_name=\"Train_F1_Score\", value=f1_base_train)\n",
    "    mv_base.set_metric(metric_name=\"Train_Precision_Score\", value=precision_base_train)\n",
    "    mv_base.set_metric(metric_name=\"Train_Recall_score\", value=recall_base_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee5f4c-e019-4444-94c9-97e414a7881f",
   "metadata": {
    "language": "python",
    "name": "_Create_PROD_Tag"
   },
   "outputs": [],
   "source": [
    "#Create tag for PROD model\n",
    "session.sql(f'CREATE OR REPLACE TAG {DB}.{SCHEMA}.PROD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce417a2-3714-4d3e-b0b7-eb8f6040ff8e",
   "metadata": {
    "language": "python",
    "name": "_Apply_Tag"
   },
   "outputs": [],
   "source": [
    "#Apply prod tag \n",
    "m = model_registry.get_model(model_name)\n",
    "m.comment = \"Loan approval prediction models\" #set model level comment\n",
    "m.set_tag(f'{DB}.{SCHEMA}.PROD', base_version_name)\n",
    "m.show_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d6ff1-3205-42e7-adae-f2f38ff0a647",
   "metadata": {
    "language": "python",
    "name": "_Predict_Base"
   },
   "outputs": [],
   "source": [
    "reg_preds = mv_base.run(test, function_name = \"predict\").rename(col('\"output_feature_0\"'), 'MORTGAGE_PREDICTION')\n",
    "\n",
    "preds_pd = reg_preds.select([\"MORTGAGERESPONSE\", \"MORTGAGE_PREDICTION\"]).to_pandas()\n",
    "f1_base_test = round(f1_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "precision_base_test = round(precision_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "recall_base_test = round(recall_score(preds_pd.MORTGAGERESPONSE, preds_pd.MORTGAGE_PREDICTION),4)\n",
    "\n",
    "#log metrics to model registry model\n",
    "mv_base.set_metric(metric_name=\"Test_F1_Score\", value=f1_base_test)\n",
    "mv_base.set_metric(metric_name=\"Test_Precision_Score\", value=precision_base_test)\n",
    "mv_base.set_metric(metric_name=\"Test_Recall_score\", value=recall_base_test)\n",
    "\n",
    "print(f'F1: {f1_base_train} \\nPrecision {precision_base_train} \\nRecall: {recall_base_train}')\n",
    "print('----------')\n",
    "print(f'F1: {f1_base_test} \\nPrecision {precision_base_test} \\nRecall: {recall_base_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b7d9e-e89b-4d96-b8cf-8660c3b1d509",
   "metadata": {
    "collapsed": false,
    "name": "_Overfit_ET"
   },
   "source": [
    "Model is still overfit let's use experiment tracking to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20464639-921c-4622-8b2f-abf796796bcd",
   "metadata": {
    "language": "python",
    "name": "_Exp_Track_Run"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.data import DataConnector\n",
    "from snowflake.ml.modeling.tune import get_tuner_context\n",
    "from snowflake.ml.modeling import tune\n",
    "from entities import search_algorithm\n",
    "import psutil\n",
    "from snowflake.ml.experiment.experiment_tracking import ExperimentTracking\n",
    "from snowflake.ml.runtime_cluster import get_ray_dashboard_url, scale_cluster\n",
    "\n",
    "st.write('Click the link below to view the ray cluster and follow along with your HPO job progress!')\n",
    "st.write('https://'+get_ray_dashboard_url())\n",
    "\n",
    "#Define dataset map\n",
    "dataset_map = {\n",
    "    \"x_train\": DataConnector.from_dataframe(train.drop(\"MORTGAGERESPONSE\", \"TIMESTAMP\", \"LOAN_ID\")),\n",
    "    \"y_train\": DataConnector.from_dataframe(train.select(\"MORTGAGERESPONSE\")),\n",
    "    \"x_test\": DataConnector.from_dataframe(test.drop(\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\")),\n",
    "    \"y_test\": DataConnector.from_dataframe(test.select(\"MORTGAGERESPONSE\"))\n",
    "    }\n",
    "\n",
    "# Scale up the cluster\n",
    "scale_cluster(2)\n",
    "\n",
    "# Define a training function, with any models you choose within it.\n",
    "def train_func():\n",
    "\n",
    "    local_session = get_active_session()\n",
    "    exp = ExperimentTracking(session=local_session)\n",
    "    \n",
    "    exp.set_experiment(\"E2E_MLOPS_HPO_Experiments\")\n",
    "    with exp.start_run():\n",
    "        # A context object provided by HPO API to expose data for the current HPO trial\n",
    "        \n",
    "        tuner_context = get_tuner_context()\n",
    "        \n",
    "        #Generate params\n",
    "        config = tuner_context.get_hyper_params()\n",
    "        dm = tuner_context.get_dataset_map()\n",
    "    \n",
    "        #Log params to experiment tracking\n",
    "        exp.log_params(config)\n",
    "        \n",
    "        #Instantiate mdoel with generated params\n",
    "        model = XGBClassifier(**config, random_state=42)\n",
    "    \n",
    "        X_train_pd = dm[\"x_train\"].to_pandas().sort_index()\n",
    "        y_train_pd = dm[\"y_train\"].to_pandas().sort_index()\n",
    "        X_test_pd = dm[\"x_test\"].to_pandas().sort_index()\n",
    "        y_test_pd = dm[\"y_test\"].to_pandas().sort_index()\n",
    "    \n",
    "        #Train model, get preds\n",
    "        model.fit(X_train_pd,y_train_pd)\n",
    "\n",
    "        #Run inference on train preds\n",
    "        train_preds = model.predict(X_train_pd)\n",
    "\n",
    "        #Run inference on test preds\n",
    "        test_preds = model.predict(X_test_pd)\n",
    "        \n",
    "        #compute metrics \n",
    "        f1_train = f1_score(y_train_pd,train_preds)\n",
    "        precision_train = precision_score(y_train_pd,train_preds)\n",
    "        recall_train = recall_score(y_train_pd,train_preds)\n",
    "\n",
    "        f1_test = f1_score(y_test_pd,test_preds)\n",
    "        precision_test = precision_score(y_test_pd,test_preds)\n",
    "        recall_test = recall_score(y_test_pd,test_preds)\n",
    "    \n",
    "        metrics_to_log = {\"F1_Train\": f1_train,\n",
    "                         \"Precision_Train\": precision_train,\n",
    "                         \"Recall_Train\": recall_train,\n",
    "                         \"F1_Test\": f1_test,\n",
    "                         \"Precision_Test\": precision_test,\n",
    "                         \"Recall_Test\": recall_test,}\n",
    "    \n",
    "        #Log metrics to experiment tracking and tuner context \n",
    "        exp.log_metrics(metrics_to_log)\n",
    "    \n",
    "        tuner_context.report(metrics=metrics_to_log, model=model)\n",
    "\n",
    "        \n",
    "tuner = tune.Tuner(\n",
    "    train_func=train_func,\n",
    "    search_space={\n",
    "        \"max_depth\": tune.randint(1, 30),\n",
    "        \"learning_rate\": tune.uniform(0.01, 0.5),\n",
    "        \"n_estimators\": tune.randint(50, 150),\n",
    "    },\n",
    "    tuner_config=tune.TunerConfig(\n",
    "        metric=\"F1_Test\",\n",
    "        mode=\"max\",\n",
    "        search_alg=search_algorithm.RandomSearch(random_state=101),\n",
    "        num_trials=4, #run 4 trial runs\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07aa90d-b819-44fa-a22e-b5c76301cf86",
   "metadata": {
    "language": "python",
    "name": "_Run_EXp_Dist_HPO"
   },
   "outputs": [],
   "source": [
    "tuner_results = tuner.run(dataset_map=dataset_map)\n",
    "tuner_results.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca442d-3313-4516-8c49-de7c4dc31f94",
   "metadata": {
    "language": "python",
    "name": "_Best_model"
   },
   "outputs": [],
   "source": [
    "#Select best model results and inspect configuration\n",
    "tuned_model = tuner_results.best_model\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3360a-04f8-4784-a683-610fbea8f343",
   "metadata": {
    "language": "python",
    "name": "_Model_Preds"
   },
   "outputs": [],
   "source": [
    "#Generate predictions\n",
    "xgb_opt_preds = tuned_model.predict(train_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n",
    "\n",
    "#Generate performance metrics\n",
    "f1_opt_train = round(f1_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n",
    "precision_opt_train = round(precision_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n",
    "recall_opt_train = round(recall_score(train_pd.MORTGAGERESPONSE, xgb_opt_preds),4)\n",
    "\n",
    "print(f'Train Results: \\nF1: {f1_opt_train} \\nPrecision {precision_opt_train} \\nRecall: {recall_opt_train}')\n",
    "\n",
    "#Generate test predictions\n",
    "xgb_opt_preds_test = tuned_model.predict(test_pd.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"],axis=1))\n",
    "\n",
    "#Generate performance metrics on test data\n",
    "f1_opt_test = round(f1_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "precision_opt_test = round(precision_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "recall_opt_test = round(recall_score(test_pd.MORTGAGERESPONSE, xgb_opt_preds_test),4)\n",
    "\n",
    "print(f'Test Results: \\nF1: {f1_opt_test} \\nPrecision {precision_opt_test} \\nRecall: {recall_opt_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cee712-54fb-4607-b99e-67386a6a5a53",
   "metadata": {
    "language": "python",
    "name": "_Log_HPO_Model"
   },
   "outputs": [],
   "source": [
    "#Log the optimized model to the model registry (if not already there)\n",
    "optimized_version_name = 'XGB_Optimized'\n",
    "\n",
    "try:\n",
    "    #Check for existing model\n",
    "    mv_opt = model_registry.get_model(model_name).version(optimized_version_name)\n",
    "    print(\"Found existing model version!\")\n",
    "except:\n",
    "    #Log model to registry\n",
    "    print(\"Logging new model version...\")\n",
    "    mv_opt = model_registry.log_model(\n",
    "        model_name=model_name,\n",
    "        model=tuned_model, \n",
    "        version_name=optimized_version_name,\n",
    "        sample_input_data = train.drop([\"TIMESTAMP\", \"LOAN_ID\", \"MORTGAGERESPONSE\"]).limit(100),\n",
    "        comment = f\"\"\"HPO ML model for predicting loan approval likelihood.\n",
    "            This model was trained using XGBoost classifier.\n",
    "            Optimized hyperparameters used were:\n",
    "            max_depth={tuned_model.max_depth}, \n",
    "            n_estimators={tuned_model.n_estimators}, \n",
    "            learning_rate = {tuned_model.learning_rate}, \n",
    "            \"\"\",\n",
    "        target_platforms= [\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n",
    "        options= {\"enable_explainability\": True}\n",
    "\n",
    "    )\n",
    "    #Set metrics\n",
    "    mv_opt.set_metric(metric_name=\"Train_F1_Score\", value=f1_opt_train)\n",
    "    mv_opt.set_metric(metric_name=\"Train_Precision_Score\", value=precision_opt_train)\n",
    "    mv_opt.set_metric(metric_name=\"Train_Recall_score\", value=recall_opt_train)\n",
    "\n",
    "    mv_opt.set_metric(metric_name=\"Test_F1_Score\", value=f1_opt_test)\n",
    "    mv_opt.set_metric(metric_name=\"Test_Precision_Score\", value=precision_opt_test)\n",
    "    mv_opt.set_metric(metric_name=\"Test_Recall_score\", value=recall_opt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb7a33-e484-4dc5-9e9e-92dab312f992",
   "metadata": {
    "language": "python",
    "name": "_Base_Default"
   },
   "outputs": [],
   "source": [
    "#Here we see the BASE version is our default version\n",
    "model_registry.get_model(model_name).default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7ed86-4675-4942-8d9c-af64c9b5330c",
   "metadata": {
    "language": "python",
    "name": "_Set_Opt_Default"
   },
   "outputs": [],
   "source": [
    "reg = Registry(session=session, database_name= DB, schema_name= SCHEMA)\n",
    "\n",
    "recent_model_name = reg.get_model(model_name).last().version_name\n",
    "m.default = recent_model_name\n",
    "m.default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8f61d-00a2-4ece-8153-386dc2acdc1b",
   "metadata": {
    "collapsed": false,
    "name": "_Explain"
   },
   "source": [
    "Explain our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf47c4-d1fa-4a83-a45c-54ae64fa3aad",
   "metadata": {
    "language": "python",
    "name": "_Shap"
   },
   "outputs": [],
   "source": [
    "#create a sample of 1000 records\n",
    "test_pd_sample=test_pd.rename(columns=rename_dict).sample(n=2500, random_state = 100).reset_index(drop=True)\n",
    "\n",
    "#Compute shapley values for each model\n",
    "base_shap_pd = mv_base.run(test_pd_sample, function_name=\"explain\")\n",
    "opt_shap_pd = mv_opt.run(test_pd_sample, function_name=\"explain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a12737-60d3-44cd-a025-255de2fdbb15",
   "metadata": {
    "language": "python",
    "name": "_Show_Shap"
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.monitoring import explain_visualize\n",
    "\n",
    "feat_df=test_pd_sample.drop([\"MORTGAGERESPONSE\",\"TIMESTAMP\", \"LOAN_ID\"],axis=1)\n",
    "\n",
    "explain_visualize.plot_influence_sensitivity(base_shap_pd, feat_df, figsize=(750, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60154f-4bd3-4cff-accf-fc450b0e7d0a",
   "metadata": {
    "language": "python",
    "name": "_Monitoring"
   },
   "outputs": [],
   "source": [
    "train.write.save_as_table(f\"{DB}.{SCHEMA}.DEMO_MORTGAGE_LENDING_TRAIN_{VERSION_NUM}\", mode=\"overwrite\")\n",
    "test.write.save_as_table(f\"{DB}.{SCHEMA}.DEMO_MORTGAGE_LENDING_TEST_{VERSION_NUM}\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e00b69-ae60-4adf-bfd6-9c0eefe5949f",
   "metadata": {
    "language": "python",
    "name": "_Create_Stage"
   },
   "outputs": [],
   "source": [
    "session.sql(f'CREATE stage IF NOT EXISTS {DB}.{SCHEMA}.ML_STAGE').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27489a-8a43-4ff9-b0d4-7f31638670bc",
   "metadata": {
    "language": "python",
    "name": "_Inference_SPROC"
   },
   "outputs": [],
   "source": [
    "from snowflake import snowpark\n",
    "\n",
    "def demo_inference_sproc(session: snowpark.Session, table_name: str, modelname: str, modelversion: str) -> str:\n",
    "\n",
    "    reg = Registry(session=session)\n",
    "    m = reg.get_model(model_name)  # Fetch the model using the registry\n",
    "    mv = m.version(modelversion)\n",
    "    \n",
    "    input_table_name=table_name\n",
    "    pred_col = f'{modelversion}_PREDICTION'\n",
    "\n",
    "    # Read the input table to a dataframe\n",
    "    df = session.table(input_table_name)\n",
    "    results = mv.run(df, function_name=\"predict\").select(\"LOAN_ID\",'\"output_feature_0\"').withColumnRenamed('\"output_feature_0\"', pred_col)\n",
    "    # 'results' is the output DataFrame with predictions\n",
    "\n",
    "    final = df.join(results, on=\"LOAN_ID\", how=\"full\")\n",
    "    # Write results back to Snowflake table\n",
    "    final.write.save_as_table(table_name, mode='overwrite',enable_schema_evolution=True)\n",
    "\n",
    "    return \"Success\"\n",
    "\n",
    "# Register the stored procedure\n",
    "session.sproc.register(\n",
    "    func=demo_inference_sproc,\n",
    "    name=\"model_inference_sproc\",\n",
    "    replace=True,\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@ML_STAGE\",\n",
    "    packages=['joblib', 'snowflake-snowpark-python', 'snowflake-ml-python'],\n",
    "    return_type=StringType()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df42a5-b232-4751-81d3-b50aa9a4c74e",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "sql",
    "name": "_inf1"
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe1369-80e4-4a23-8d2d-8356a71c7d20",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "sql",
    "name": "_inf2"
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}','{{model_name}}', '{{base_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36764a7d-a756-4aea-8e3d-74fb49257aab",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "sql",
    "name": "_inf3"
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}','{{model_name}}', '{{optimized_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754355b-c2ad-4ece-879b-2e8cc277048f",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": true,
    "language": "sql",
    "name": "_inf4"
   },
   "outputs": [],
   "source": [
    "CALL model_inference_sproc('DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}','{{model_name}}', '{{optimized_version_name}}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02afb7-7878-4a64-8459-005cb7c91c83",
   "metadata": {
    "language": "sql",
    "name": "_Run"
   },
   "outputs": [],
   "source": [
    "select TIMESTAMP, LOAN_ID, INCOME, LOAN_AMOUNT, XGB_BASE_PREDICTION, XGB_OPTIMIZED_PREDICTION, MORTGAGERESPONSE \n",
    "FROM DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}} \n",
    "limit 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8589ce-f87d-4363-892e-a7911fdc3a13",
   "metadata": {
    "language": "sql",
    "name": "_Test_monitor"
   },
   "outputs": [],
   "source": [
    "ALTER TABLE DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n",
    "ADD COLUMN IF NOT EXISTS LOAN_PURPOSE VARCHAR(50);\n",
    "\n",
    "\n",
    "UPDATE DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n",
    "SET LOAN_PURPOSE = CASE\n",
    "    WHEN LOAN_PURPOSE_NAME_HOME_IMPROVEMENT = 1 THEN 'HOME_IMPROVEMENT'\n",
    "    WHEN LOAN_PURPOSE_NAME_HOME_PURCHASE = 1 THEN 'HOME_PURCHASE'\n",
    "    WHEN LOAN_PURPOSE_NAME_REFINANCING = 1 THEN 'REFINANCING'\n",
    "    ELSE 'OTHER'\n",
    "END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab591ab-e418-4933-adab-9812cdf8c84f",
   "metadata": {
    "language": "sql",
    "name": "_Train_Monitor"
   },
   "outputs": [],
   "source": [
    "ALTER TABLE DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n",
    "ADD COLUMN IF NOT EXISTS LOAN_PURPOSE VARCHAR(50);\n",
    "\n",
    "\n",
    "UPDATE DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n",
    "SET LOAN_PURPOSE = CASE\n",
    "    WHEN LOAN_PURPOSE_NAME_HOME_IMPROVEMENT = 1 THEN 'HOME_IMPROVEMENT'\n",
    "    WHEN LOAN_PURPOSE_NAME_HOME_PURCHASE = 1 THEN 'HOME_PURCHASE'\n",
    "    WHEN LOAN_PURPOSE_NAME_REFINANCING = 1 THEN 'REFINANCING'\n",
    "    ELSE 'OTHER'\n",
    "END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2194756-14db-4332-87c9-44b967df8c74",
   "metadata": {
    "language": "sql",
    "name": "_Loan_Purpose"
   },
   "outputs": [],
   "source": [
    "SELECT LOAN_PURPOSE_NAME_HOME_PURCHASE, LOAN_PURPOSE_NAME_HOME_IMPROVEMENT, LOAN_PURPOSE_NAME_REFINANCING, LOAN_PURPOSE FROM DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}} limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508d26e-d14f-4160-8355-425d3c56b2cb",
   "metadata": {
    "language": "sql",
    "name": "_Create_Monitor"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_BASE_MODEL_MONITOR\n",
    "WITH\n",
    "    MODEL={{model_name}}\n",
    "    VERSION={{base_version_name}}\n",
    "    FUNCTION=predict\n",
    "    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n",
    "    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n",
    "    TIMESTAMP_COLUMN=TIMESTAMP\n",
    "    PREDICTION_CLASS_COLUMNS=(XGB_BASE_PREDICTION)  \n",
    "    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n",
    "    ID_COLUMNS=(LOAN_ID)\n",
    "    SEGMENT_COLUMNS = ('LOAN_PURPOSE')\n",
    "    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n",
    "    REFRESH_INTERVAL='12 hours'\n",
    "    AGGREGATION_WINDOW='1 day';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e2cfc-0511-4393-a191-244ef5350359",
   "metadata": {
    "language": "sql",
    "name": "_Opt_Monitor"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE MODEL MONITOR MORTGAGE_LENDING_OPTIMIZED_MODEL_MONITOR\n",
    "WITH\n",
    "    MODEL={{model_name}}\n",
    "    VERSION={{optimized_version_name}}\n",
    "    FUNCTION=predict\n",
    "    SOURCE=DEMO_MORTGAGE_LENDING_TEST_{{VERSION_NUM}}\n",
    "    BASELINE=DEMO_MORTGAGE_LENDING_TRAIN_{{VERSION_NUM}}\n",
    "    TIMESTAMP_COLUMN=TIMESTAMP\n",
    "    PREDICTION_CLASS_COLUMNS=(XGB_OPTIMIZED_PREDICTION)  \n",
    "    ACTUAL_CLASS_COLUMNS=(MORTGAGERESPONSE)\n",
    "    ID_COLUMNS=(LOAN_ID)\n",
    "    SEGMENT_COLUMNS = ('LOAN_PURPOSE')\n",
    "    WAREHOUSE={{COMPUTE_WAREHOUSE}}\n",
    "    REFRESH_INTERVAL='12 hours'\n",
    "    AGGREGATION_WINDOW='1 day';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "chase.romano@snowflake.com",
   "authorId": "4927852566776",
   "authorName": "CHASE",
   "lastEditTime": 1764797922341,
   "notebookId": "a7njtivqgwddrjoorkpv",
   "sessionId": "f6904512-eca2-44db-9b9b-2d0ee79eb2cf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
